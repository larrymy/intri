set.seed(223)
intrain <- createDataPartition(y = iris[,1], p = q, list = F) #60% training, 40% validation set
train <<- iris[intrain,]; test <<- iris[-intrain,]
sapply(c("rf"), FUN=function(j){
glm_model <- train(Species~., data=train, method=j)
pred_1 <- predict(glm_model, newdata = test)
RMSE(pred_1, test[,"Species"])
})
})
p <- seq(0.1, 0.9, 0.1)
sapply(p, FUN = function(q){
set.seed(223)
intrain <- createDataPartition(y = iris[,1], p = q, list = F) #60% training, 40% validation set
train <<- iris[intrain,]; test <<- iris[-intrain,]
sapply(c("rf"), FUN=function(j){
glm_model <- train(Species~., data=train, method=j)
pred_1 <- predict(glm_model, newdata = test)
sum(pred_1 == test[,"Species"])/nrow(test)
})
})
pv <- function(n,r,CF,FV){
v <- 1/(1+r)
p <- CF*(1-v^n)/r + FV*v^n
return(p)
}
pv(1,0.01,1,1)
set.seed(400)
nsim <- round(runif(5000,1,30),0)
rsim <- runif(5000,0.001,0.05)
CFsim <- runif(5000,1,3)
FVsim <- runif(5000,1,5)
p <- pv(nsim, rsim, CFsim, FVsim)
set.seed(400)
size <- 5000
nsim <- round(runif(size,1,30),0)
rsim <- runif(size,0.001,0.05)
CFsim <- runif(size,1,3)
FVsim <- runif(size,1,5)
p <- pv(nsim, rsim, CFsim, FVsim)
data <- data.frame(n = nsim, r = rsim, CFsim = CFsim, FVsim = FVsim, p = p)
partition <- 0.75
index <- sample(1:nrow(data),round(partition*nrow(data)))
train <- data[index,]
test <- data[-index,]
lm.fit <- glm(p~., data=train)
summary(lm.fit)
pr.lm <- predict(lm.fit,test)
MSE.lm <- sum((pr.lm - test$p)^2)/nrow(test)
MSE.lm
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
system.time({
library(neuralnet)
n <- names(train_)
f <- as.formula(paste("p ~", paste(n[!n %in% "p"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=rep(25,3),linear.output=T)
# Visual plot of the model
# plot(nn)
# Predict
pr.nn <- compute(nn,test_[,1:4])
# Results from NN are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$p)-min(data$p))+min(data$p)
test.r <- (test_$p)*(max(data$p)-min(data$p))+min(data$p)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
# Compare the two MSEs
print(paste(MSE.lm,MSE.nn))
})
system.time({
n <- names(train_)
f <- as.formula(paste("p ~", paste(n[!n %in% "p"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=rep(50,3),linear.output=T)
# Visual plot of the model
# plot(nn)
# Predict
pr.nn <- compute(nn,test_[,1:4])
# Results from NN are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$p)-min(data$p))+min(data$p)
test.r <- (test_$p)*(max(data$p)-min(data$p))+min(data$p)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
# Compare the two MSEs
print(paste(MSE.lm,MSE.nn))
})
system.time({
n <- names(train_)
f <- as.formula(paste("p ~", paste(n[!n %in% "p"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=rep(25,10),linear.output=T)
# Visual plot of the model
# plot(nn)
# Predict
pr.nn <- compute(nn,test_[,1:4])
# Results from NN are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$p)-min(data$p))+min(data$p)
test.r <- (test_$p)*(max(data$p)-min(data$p))+min(data$p)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
# Compare the two MSEs
print(paste(MSE.lm,MSE.nn))
})
system.time({
nnode <- 25
nlayer <- 20
n <- names(train_)
f <- as.formula(paste("p ~", paste(n[!n %in% "p"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=rep(nnode,nlayer),linear.output=T)
# Visual plot of the model
# plot(nn)
# Predict
pr.nn <- compute(nn,test_[,1:4])
# Results from NN are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$p)-min(data$p))+min(data$p)
test.r <- (test_$p)*(max(data$p)-min(data$p))+min(data$p)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
# Compare the two MSEs
print(paste(nnode, nlayer))
print(paste(MSE.lm,MSE.nn))
})
library(neuralnet)
pv <- function(n,r,CF,FV){
v <- 1/(1+r)
p <- CF*(1-v^n)/r + FV*v^n
return(p)
}
pv(1,0.01,1,1)
set.seed(400)
size <- 10000
nsim <- round(runif(size,1,30),0)
rsim <- runif(size,0.001,0.05)
CFsim <- runif(size,1,3)
FVsim <- runif(size,1,5)
p <- pv(nsim, rsim, CFsim, FVsim)
data <- data.frame(n = nsim, r = rsim, CFsim = CFsim, FVsim = FVsim, p = p)
partition <- 0.75
index <- sample(1:nrow(data),round(partition*nrow(data)))
train <- data[index,]
test <- data[-index,]
# Fitting linear model
lm.fit <- glm(p~., data=train)
summary(lm.fit)
# Predicted data from lm
pr.lm <- predict(lm.fit,test)
# Test MSE
MSE.lm <- sum((pr.lm - test$p)^2)/nrow(test)
MSE.lm
# Scaling data for the NN
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
# NN training
system.time({
nnode <- 25
nlayer <- 20
n <- names(train_)
f <- as.formula(paste("p ~", paste(n[!n %in% "p"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=rep(nnode,nlayer),linear.output=T)
# Visual plot of the model
# plot(nn)
# Predict
pr.nn <- compute(nn,test_[,1:4])
# Results from NN are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$p)-min(data$p))+min(data$p)
test.r <- (test_$p)*(max(data$p)-min(data$p))+min(data$p)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
# Compare the two MSEs
print(paste(nnode, nlayer))
print(paste(MSE.lm,MSE.nn))
})
# data.frame(test.r, pr.nn_, pr.lm)
library(neuralnet)
pv <- function(n,r,CF,FV){
v <- 1/(1+r)
p <- CF*(1-v^n)/r + FV*v^n
return(p)
}
pv(1,0.01,1,1)
set.seed(400)
size <- 20000
nsim <- round(runif(size,1,30),0)
rsim <- runif(size,0.001,0.05)
CFsim <- runif(size,1,3)
FVsim <- runif(size,1,5)
p <- pv(nsim, rsim, CFsim, FVsim)
data <- data.frame(n = nsim, r = rsim, CFsim = CFsim, FVsim = FVsim, p = p)
partition <- 0.75
index <- sample(1:nrow(data),round(partition*nrow(data)))
train <- data[index,]
test <- data[-index,]
# Fitting linear model
lm.fit <- glm(p~., data=train)
summary(lm.fit)
# Predicted data from lm
pr.lm <- predict(lm.fit,test)
# Test MSE
MSE.lm <- sum((pr.lm - test$p)^2)/nrow(test)
MSE.lm
# Scaling data for the NN
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
# NN training
system.time({
nnode <- 100
nlayer <- 6
n <- names(train_)
f <- as.formula(paste("p ~", paste(n[!n %in% "p"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=rep(nnode,nlayer),linear.output=T)
# Visual plot of the model
# plot(nn)
# Predict
pr.nn <- compute(nn,test_[,1:4])
# Results from NN are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$p)-min(data$p))+min(data$p)
test.r <- (test_$p)*(max(data$p)-min(data$p))+min(data$p)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
# Compare the two MSEs
print(paste(nnode, nlayer))
print(paste(MSE.lm,MSE.nn))
})
# data.frame(test.r, pr.nn_, pr.lm)
print(paste0("size: ", size))
print(paste0("nnode, nlayer: ", nnode, ", ", nlayer))
print(paste0("MSE.lm, MSE.nn: ", MSE.lm, ", ", MSE.nn))
summary((pr.nn_/test.r - 1))a
summary((pr.nn_/test.r - 1))
library(neuralnet)
pv <- function(n,r,CF,FV){
v <- 1/(1+r)
p <- CF*(1-v^n)/r + FV*v^n
p <- 2*n + r*3 + CF*5 + FV*6
return(p)
}
pv(1,0.01,1,1)
set.seed(400)
size <- 20000
nsim <- round(runif(size,1,30),0)
rsim <- runif(size,0.001,0.05)
CFsim <- runif(size,1,3)
FVsim <- runif(size,1,5)
p <- pv(nsim, rsim, CFsim, FVsim)
data <- data.frame(n = nsim, r = rsim, CFsim = CFsim, FVsim = FVsim, p = p)
partition <- 0.75
index <- sample(1:nrow(data),round(partition*nrow(data)))
train <- data[index,]
test <- data[-index,]
# Fitting linear model
lm.fit <- glm(p~., data=train)
summary(lm.fit)
# Predicted data from lm
pr.lm <- predict(lm.fit,test)
# Test MSE
MSE.lm <- sum((pr.lm - test$p)^2)/nrow(test)
MSE.lm
# Scaling data for the NN
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
# NN training
system.time({
nnode <- 100
nlayer <- 6
n <- names(train_)
f <- as.formula(paste("p ~", paste(n[!n %in% "p"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=rep(nnode,nlayer),linear.output=T)
# Visual plot of the model
# plot(nn)
# Predict
pr.nn <- compute(nn,test_[,1:4])
# Results from NN are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$p)-min(data$p))+min(data$p)
test.r <- (test_$p)*(max(data$p)-min(data$p))+min(data$p)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
# Compare the two MSEs
print(paste0("size: ", size))
print(paste0("nnode, nlayer: ", nnode, ", ", nlayer))
print(paste0("MSE.lm, MSE.nn: ", MSE.lm, ", ", MSE.nn))
summary((pr.nn_/test.r - 1))
})
# data.frame(test.r, pr.nn_, pr.lm)
library(neuralnet)
pv <- function(n,r,CF,FV){
v <- 1/(1+r)
p <- CF*(1-v^n)/r + FV*v^n
# p <- 2*n + r*3 + CF*5 + FV*6
p <- 2*n + r*3 + CF*5 + FV^2
return(p)
}
pv(1,0.01,1,1)
set.seed(400)
size <- 20000
nsim <- round(runif(size,1,30),0)
rsim <- runif(size,0.001,0.05)
CFsim <- runif(size,1,3)
FVsim <- runif(size,1,5)
p <- pv(nsim, rsim, CFsim, FVsim)
data <- data.frame(n = nsim, r = rsim, CFsim = CFsim, FVsim = FVsim, p = p)
partition <- 0.75
index <- sample(1:nrow(data),round(partition*nrow(data)))
train <- data[index,]
test <- data[-index,]
# Fitting linear model
lm.fit <- glm(p~., data=train)
summary(lm.fit)
# Predicted data from lm
pr.lm <- predict(lm.fit,test)
# Test MSE
MSE.lm <- sum((pr.lm - test$p)^2)/nrow(test)
MSE.lm
# Scaling data for the NN
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
# NN training
system.time({
nnode <- 50
nlayer <- 4
n <- names(train_)
f <- as.formula(paste("p ~", paste(n[!n %in% "p"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=rep(nnode,nlayer),linear.output=T)
# Visual plot of the model
# plot(nn)
# Predict
pr.nn <- compute(nn,test_[,1:4])
# Results from NN are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$p)-min(data$p))+min(data$p)
test.r <- (test_$p)*(max(data$p)-min(data$p))+min(data$p)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
# Compare the two MSEs
print(paste0("size: ", size))
print(paste0("nnode, nlayer: ", nnode, ", ", nlayer))
print(paste0("MSE.lm, MSE.nn: ", MSE.lm, ", ", MSE.nn))
summary((pr.nn_/test.r - 1))
})
# data.frame(test.r, pr.nn_, pr.lm)
install.packages("gmatrix")
install.packages("gmatrix")
ghit::install_github("njm18/gmatrix")
install.packages("gmatrix")
install.packages("gmatrix")
library(httr)
library(ymd)
#daily all stocks
# https://api.intrinio.com/prices/exchange.csv?identifier=^XKLS&price_date=2017-09-21
# https://api.intrinio.com/prices.csv?ticker=$SPX
# https://api.intrinio.com/prices.csv?ticker=$SPX
# https://api.intrinio.com/prices.csv?identifier=WLW:MK
# https://d82a8b255816b922a436ab6ffb177ec3:92ad8da92b80534003d9f134ec1f82a5@api.intrinio.com/prices.csv?identifier=WLW:MK
# download.file("https://d82a8b255816b922a436ab6ffb177ec3:92ad8da92b80534003d9f134ec1f82a5@api.intrinio.com/prices.csv?identifier=WLW:MK", destfile = "test.csv")
#https://api.intrinio.com/securities?exch_symbol=
url_csv <- function(){
price_base_1 <- "https://"
price_base_2 <- "@api.intrinio.com/securities.csv?exch_symbol=^XKLS"
username <- "d82a8b255816b922a436ab6ffb177ec3"
password <- "92ad8da92b80534003d9f134ec1f82a5"
price <- paste(price_base_1, username, ":", password, price_base_2,sep="")
date_char <- gsub(pattern = "-", replacement = "", x = Sys.Date())
if(!dir.exists("xkls_list_of_securities")){
dir.create("xkls_list_of_securities")
}
fname <- paste0("./xkls_list_of_securities/", date_char, "_xkls.csv")
download.file(url = price, destfile = fname)
return(fname)
}
prices <- function(ticker){
price_base <- "https://api.intrinio.com/prices?identifier="
username <- "d82a8b255816b922a436ab6ffb177ec3"
password <- "92ad8da92b80534003d9f134ec1f82a5"
price <- paste(price_base,ticker,sep="")
tp <- GET(price, authenticate(username, password, type = "basic"))
z <- unlist(content(tp,"parsed"))
n=length(z)
b=as.data.frame(matrix(z[1:(n-5)],(n-5)/13, byrow = T))
names(b)=names(z)[1:13]
return(b)
}
prices_csv <- function(ticker, name){
price_base_1 <- "https://"
price_base_2 <- "@api.intrinio.com/prices.csv?identifier="
username <- "d82a8b255816b922a436ab6ffb177ec3"
password <- "92ad8da92b80534003d9f134ec1f82a5"
price <- paste(price_base_1, username, ":", password, price_base_2, ticker,sep="")
fname <- paste0(name, "_", strsplit(ticker, ":")[[1]][1], ".csv")
download.file(url = price, destfile = fname)
# b <- read.csv(price, stringsAsFactors = F)
# tp <- GET(price, authenticate(username, password, type = "basic"))
# z <- unlist(content(tp,"parsed"))
# n=length(z)
# b=as.data.frame(matrix(z[1:(n-5)],(n-5)/13, byrow = T))
# names(b)=names(z)[1:13]
# return(z)
}
# 1 stock
# setwd("C:/Users/jy/Desktop/")
# prices_csv("PENT:MK")
# mass import
setwd("C:/Users/jy/Desktop/intri")
#get all securities
filename <- url_csv() #export list of xkls securities, and return the <filename.csv>
all_securities <- read.csv(file=filename, stringsAsFactors = F, skip = 1)
# all_securities <- read.csv("securities_xkls.csv", stringsAsFactors = F, skip = 1)
u1 <- all_securities[, "SECURITY_TYPE"] == "Common Stock"
all_figi_ticker <- all_securities[u1, "FIGI_TICKER"]
all_ticker <- all_securities[u1, "TICKER"]
if(!dir.exists("data")){dir.create("data")}
setwd("C:/Users/jy/Desktop/intri/data")
date_char <- gsub(pattern = "-", replacement = "", x = Sys.Date())
dir.create(date_char)
setwd(paste0("C:/Users/jy/Desktop/intri/data/", date_char))
N <- length(all_ticker); print(N);
for(i in 1:N){
prices_csv(all_figi_ticker[i], all_ticker[i])
}
print("Done")
# a <- grep(z, pattern = "OPEN")
# b <- grep(z, pattern = "DATE")
#      N <- a-b-1
#
#      k = 11
#      b=as.data.frame(matrix(z[1:(k*(N+1))],nrow = N+1, ncol = k, byrow = F))
#        b
# RCurl::getURL(
# ticker <- "MTI:MK"
# df <- prices("WLW:MK")
# df2 <- prices_csv("MTI:MK")
# str(df2)
# nrow(df)
# z <- unlist(content(df2,"parsed"))
# base <- "https://api.intrinio.com/"
# endpoint <- "data_point"
# stock <- "AAPL"
# item1 <- "close_price"
# item2 <- "pricetoearnings"
# call1 <- paste(base,endpoint,"?","ticker","=", stock, "&","item","=",item1, sep="")
# call2 <- paste(base,endpoint,"?","ticker","=", stock, "&","item","=",item2, sep="")
#
# apple_price <- GET(call1, authenticate(username,password, type = "basic"))
# apple_pricetoearnings <- GET(call2, authenticate(username,password, type = "basic"))
#
#
# test1 <- unlist(content(apple_price,"parsed"))
# test2 <- unlist(content(apple_pricetoearnings,"parsed"))
#
# df <- data.frame(test1,test2)
daily_csv <- function(today_date = "2017-10-23"){
#https://api.intrinio.com/prices/exchange.csv?identifier=^XKLS&price_date=2017-10-23
price_base_1 <- "https://"
price_base_2 <- "@api.intrinio.com/prices/exchange.csv?identifier=^XKLS&price_date="
# today_date <- "2017-10-24"
username <- "d82a8b255816b922a436ab6ffb177ec3"
password <- "92ad8da92b80534003d9f134ec1f82a5"
price <- paste(price_base_1, username, ":", password, price_base_2, today_date, sep="")
datepart <- gsub(pattern = "-", replacement = "", x = as.character(Sys.Date()))
dirname <- paste0("daily_exchange_data_", datepart)
if(!dir.exists(  dirname  )){
dir.create(dirname)
}
date_char <- gsub(pattern = "-", replacement = "", x = today_date)
fname <- paste0("./", dirname, "/", date_char, "_daily_xkls.csv")
download.file(url = price, destfile = fname)
df_temp <- read.csv(fname, skip = 1, header = T)
print(nrow(df_temp))
if(nrow(df_temp) == 0){
file.remove(fname)
return(NA)
}else{
return(fname)
}
}
loop_daily_csv <- function(start_date = Sys.Date(), loop = 10){
loop_date <- sapply(1:loop, FUN = function(x){
return(as.character(start_date - x + 1))
})
fname_v <- sapply(loop_date, FUN = function(datee){
daily_csv(datee);
})
return(fname_v)
}
setwd("C:/Users/jy/Desktop/intri")
loop_daily_csv(loop = 5000)
# daily_csv("2017-10-23")
